# MySQL45讲笔记

## MySQL的基础架构

![](https://static001.geekbang.org/resource/image/0d/d9/0d2070e8f84c4801adbfa03bda1f98d9.png)

MySQL分为Server层和存储引擎层

Server层包括连接器、查询缓存、分析器、优化器、执行器

存储引擎层是插件形式的，支持InnoDB MyISAM Memory 等。最常用的是InnoDB。

### 连接器 

负责跟客户端建立链接、获取权限、维持和管理链接。

### 查询缓存

大多数情况下不建议使用查询缓存，因为MySQL的查询缓存失效非常频繁，一旦表更新，该表所有的查询缓存都会被清空，因此最好用于不变的配置表。

MySQL也支持按需使用的方式，需要讲query_cache_type设置成DEMAND。但在MySQL8.

0版本上已经将查询缓存整块功能删掉了。

### 分析器

分析器会先做词法分析，识别输入的SQL语句是否满足MySQL的语法。将字符串识别成表名、字段名。

### 优化器

优化器是在表里面有多个索引的时候，决定使用哪个索引。或者在一个语句有多表关联的时候，决定各个表的链接顺序。

### 执行器

执行器是执行语句，在开始执行之前需要先判断对表有没有执行查询的权限。如果有则调用引擎提供的接口。

## 日志系统

MySQL的日志模块有两种方式 redo log 和bin log。其中redo log 是InnoDB支持的一种日志方式。

#### redo log

![](https://static001.geekbang.org/resource/image/16/a7/16a7950217b3f0f4ed02db5db59562a7.png)

Redo log 使用了WAL（Write-Ahead logging）技术。即先写日志，再写磁盘。

具体来说，当有一条记录需要更新的时候，InnoDB引擎会先把记录写到redo log,并更新内存，这个时候更新就算完成了，同时会在适当的时候将操作记录更新到磁盘中。

redo log的大小是固定的，比如配置一组4哥文件，每个文件大小为1GB,那么redo log最多能存储4GB的操作。满了之后会从头开始循环写。

![](https://static001.geekbang.org/resource/image/b0/9c/b075250cad8d9f6c791a52b6a600f69c.jpg)

write pos是当前记录的位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。
checkpoint是当前要擦除的位置，也是往后推移并循环的，擦除记录前要把记录更新到数据文件中。
write pos和checkpoint之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果write pos追上checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把checkpoint推进一下。

有了redo log，InnoDB就可以保证即使数据库发了异常重启，之前提交的记录都不会丢失。这个能力称为crash-safe

#### binlog

binlog 称为归档日志。binlog 只能用于归档，没有crash-safe能力。

redo log和bin log的不同

- redo log 是InnoDB特有的 binlog 是MySQL Server实现的。所以引擎都可以使用
- redo log是物理日志，记录的是某个数据做了什么修改，bin log是逻辑日志，记录的是这个语句的原始逻辑。
- redo log 是循环写，空间固定会用完。bin log是追加写，不会覆盖以前的日志。

![](https://static001.geekbang.org/resource/image/2e/be/2e5bff4910ec189fe1ee6e2ecc7b4bbe.png)

其中redo log拆分成了两个步骤，即prepare 和commit 称为两阶段提交。2PC

### 两阶段提交

两阶段提交的用处是为了让两份日志之间逻辑一致。

#### innodb_flush_log_at_trx_commit 
设置成1的时候表示每次事务的redo log都直接持久化到磁盘。
#### sync_binlog
这个参数设置成1表示每次事务的binlog都持久化到磁盘。

## 事务

#### 隔离性和隔离级别

当数据库上有多个事务同时执行的时候，就可能出现脏读、不可重复读、幻读的问题，为了解决这些问题，就有了隔离级别的概念。

- 脏读：事务A读取了事务B更新的数据，然后B回滚，那么A读到的数据时脏数据。
- 不可重复读：事务A多次读取同一个数据，事务B在事务A多次读取的过程中，对数据做了更新操作，导致A读取到的数据不一致。
- 幻读：新增记录时，事务开始后新增的记录没有被操作。

#### 脏读
读到了不存在的数据，产生原因事务A读取了事务B更新的数据，然后B回滚了。
对应的事务隔离级别是读未提交（一个事务还没提交时，它做的变更就可以被其他事务看到）
#### 不可重复读
事务A多次读取一个数据，事务B在事务A读取过程中对数据进行操作，事务A读到的数据不一致。
对应的事务隔离级别是读提交（一个事务提交后，它做的变更才会被其他事务看到）
#### 幻读
新增记录时，事务开始后新增的记录没有被操作
对应的事务隔离级别是可重复读（一个事务执行过程中看到的数据，总是根这个事务启动时看到的数据是一致的）
导致新增的数据不能被事务执行过程中看到

总结：不可重复读侧重于修改，幻读侧重于新增或删除。一个是更新列，一个是新增或删除记录。一个需要锁行 一个需要锁表。

隔离级别越高，效率也就越低。

SQL标准的事务隔离级别包括了：读未提交、读已移交、可重复读、串行化。

- 读未提交：一个事务还没提交时，它做的变更就能被别的事务看到。 解决脏读
- 读已提交：一个事务提交之后，它做的变更才会被其他事物看到。 解决不可重复读
- 可重复读：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然未提交变更对其他事务也是不可见的。 解决幻读
- 串行化：对同一行记录，读写都加锁。

![](https://static001.geekbang.org/resource/image/7d/f8/7dea45932a6b722eb069d2264d0066f8.png)

使用上图理解下不同隔离级别下的事务情况
- 读未提交：V1、V2、V3 都是2
- 读已提交：V1 = 1、V2、V3 = 2
- 可重复读：V1、V2 = 1，V3 = 2
- 串行化： 事务B update时会锁住，直到事务Acommit之后，事务B才会执行。所以V1、V2 = 1 V3 = 2

#### 事务的启动方式
- 显示启动： begin或者start transaction commit 或者rollback
- set autocommit = 0 ，debug的时候会用到。
## 索引

常见的三种索引模型：

- 哈希表 （时间复杂度 O(1) 但是是无序的，查找需要全部扫描一遍，适用于等值查询）
- 有序数组 （可以等值查询和范围查询，但是新增元素后需要维护后边的所有记录，只适用于静态存储引擎）
- 搜索树（树的查询复杂度是O(log(N)),更新的时间复杂度也是O(log(N))） 

根据叶子结点的内容，索引类型可以分为主键索引和非主键索引。

主键索引的叶子结点存的是整行数据。在InnoDB中也称为聚簇索引。

非主键索引的叶子结点存的是主键的值，在InnoDB中也称为二级索引。

- 如果是主键索引，只需要搜索ID这颗B+树
- 如果是非主键缩索引，则查到ID之后还需要再到ID索引树搜索一次，这个过程称为回表。

因此我们在应用中应该尽量使用主键索引。

### 索引维护
B+树为了维护索引有序性，在插入新值的时候需要做必要的维护。
如果数据页已满，需要申请一个新的数据页，然后挪部分数据过去，这个过程称为页分裂。
同时页分裂操作还会影响数据页的利用率，页分裂之后整体空间利用率降低大约50%

当然也有页合并，两个相邻的页删除了数据，利用率很低之后会将数据页做合并。

### 覆盖索引

定义：索引已经覆盖了我们的查询需求，称为覆盖索引。

比如ID在索引树上，则select ID from table where k between 1  and 5 ，结果集ID就在索引树上，因此无需回表，可以提升查询性能。

### 最左原则

查询过程是从左至右走索引的。 

在建立联合索引的时候，如何安排索引内的字段顺序？

第一原则是通过调整顺序，可以少维护一个索引，那么这个顺序往往是需要优先考虑采用的。

不符合最左前缀的部分 会使用索引下推，在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表的次数。

### 索引下推
在索引内部就判断了字段是否满足要求，这种操作称为索引下推。这个功能时在MySQL 5.6 引入的。
可以在索引遍历过程中对索引包含的字段先做判断，世界过滤掉不满足条件的记录，减少回表次数。

### 补充概念 DDL和DML
DDL (Data Define language) 数据定义语言 ，对数据库和表进行管理
DML (Data Manipulate language) 数据操作语言,CRUD

### 全局锁

全局锁就是对整个数据库实例加锁，命令是Flush tables with read lock。

典型使用场景是做全库逻辑备份。


### 表锁

MySQL的表级别的锁有两种，表锁和元数据锁。

表锁的语法是lock tables  read/write

元数据锁MDL不需要显示使用，在访问一个表的时候会被自动加上。MDL的作用是保证读写的正确性。保证多线程下拿到的表结构一致。
#### 给小表加锁时也有可能阻塞
- 长事务不提交就会一直占着MDL锁
- 热点表查询频率高时MDL一直有锁

长事务可以kill掉这个事务或者等事务结束后执行alter

热点表可以在alter table语句里面加一个等待时间
```mysql
ALTER TABLE tbl_name WAIT N add column ... 
```

### 行锁

MySQL的行锁是由引擎层自己实现的。不是所有的引擎都支持行锁，比如MyISAM就不支持。

### 死锁和死锁检测

- 设置锁的超时时间
- 发起死锁检测
正常情况下我们会采用第二种策略（主动死锁检测）

### MVCC

同一条记录在系统中可以存在多个版本，成为数据库的多版本并发控制（MVCC）

InnoDB中每个事务都有一个唯一事务ID，是按申请顺序严格递增的。

每行数据也都是有多个版本的，每次事务更新数据的时候，都会生成一个新的数据版本，并且把事务id赋值给这个数据版本的事务ID，记为row trx_id。

InnoDB 的行数据有多个版本，每个数据版本有自己的 row trx_id，每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据 row trx_id 和一致性视图确定数据版本的可见性。

- 对于可重复读，查询只承认在事务启动前就已经提交完成的数据
- 对于读提交，查询只承认在语句启动前就已经提交完成的数据

而当前读，总数读取已经提交完成的最新版本

## 实践

### 普通索引和唯一索引应该怎么选择

MySQL 提供了一个change buffer ，将更新操作先记录在里边，减少读磁盘，语句的执行速度会有很明显的提升。

- 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，就插入这个值，语句执行结束。
- 对于普通索引来说，将更新记录在change buffer ，语句执行就结束了。

所以唯一索引没有用到change buffer

因此对于写多读少的业务（如日志、账单类系统）change buffer 使用效果最好，也就是说使用普通索引。

反过来说一个查多的业务，先记录在change buffer ，但之后由于马上要访问这个数据页，会立即出发merge 写到磁盘中，反而会增加change buffer的维护代价。

### MySQL选错索引的情况

优化器会根据扫描行数、是否使用临时表、是否排序等因素综合选取索引。

其中扫描行数是根据索引的基数判断的。

采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。

使用analyze table 表名 ，可以用来重新统计索引信息。

而对于其他优化器误判的情况，你可以在应用端用 force index 来强行指定索引，也可以通过修改语句来引导优化器，还可以通过增加或者删除索引来绕过这个问题。

### 字符串添加索引

给字符串添加索引可以使用前缀索引，定义好长度，就可以做到既节省空间，有不用额外增加太多的查询成本。

但是使用前缀索引就用不上覆盖索引对查询性能的优化了，这两者之间需要取舍。

### 刷脏页造成的MySQL“抖一下”

当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。

刷脏页的四种场景

- redo log 写满
- 内存不够用
- MySQL空闲时
- MySQL正常关闭

其中1和2会影响用户体验。需要设置对应的配置优化脏页刷新频率。

### 删数据表的操作
删除数据只是标记为可复用，但磁盘上文件不会变小。
删除数据之后需要重建表 命令为alter table 表名 engine=InnoDB

### SELECT count(*)的操作

- MyISAM 将一个表的总行数存在磁盘上，因此MyISAM的count(*)的效率很高，但也仅限于不带where的语句。
- InnoDB需要一行行地从引擎中读出来，累加。

InnoDB不采用维护一个总行数的原因是因为事务设计（MVCC）的关系。当多个事务存在insert的时候 不符合可重复读的隔离级别。

按照效率排序的话，count(字段)<count(主键id)<count(1)≈count(*)，所以我建议你，尽量使用count(*)。

### order by
- MySQL会为每个线程分配一个内存（sort_buffer） 用于排序该内存大小为sort_buffer_size 
- - 如果排序的数据量小于sort_buffer_size，排序将会在内存中完成.
- - 如果排序数据量很大，内存中无法存下这么多数据，则会使用磁盘临时文件来辅助排序，也称外部排序。
- - 在使用外部排序时，MySQl会分成好几份单独的临时文件用来存放排序后的数据，然后将这些文件合并成一个大文件。这里使用的算法是归并排序算法。
- MySQL会通过遍历索引将满足条件的数据读到sort_buffer，并且按照排序字段进行快速排序。
- - 如果查询的字段不包含在辅助索引中，需要按照辅助索引记录的主键返回的聚集索引去除所需要的字段（回表）
- - 按照情况建立联合索引来避免排序所带来的性能损耗，允许的情况下也可以建立覆盖索引来避免回表
全字段排序
- 通过索引将所需要的字段全部读到sort_buffer中
- 按照排序字段进行排序
- 将结果返回给客户端
  缺点：
- 造成sort_buffer中存放不下很多数据，因为除了排序字段还存放其他字段，对sort_buffer的利用效率不高
- 当所需排序数据量很大时，会有很多的临时文件，排序性能也会很差
  优点：
- MySQL认为内存足够大时会优先选择全字段排序，因为这种方式比rowid 排序避免了一次回表操作

rowid排序
- 通过控制排序的行数据的长度来让sort_buffer中尽可能多的存放数据，max_length_for_sort_data
- 只将需要排序的字段和主键读取到sort_buffer中，并按照排序字段进行排序
- 按照排序后的顺序，取id进行回表取出想要获取的数据
- 将结果集返回给客户端

缺点：回表的操作是随机IO，会造成大量的随机读，不一定就比全字段排序减少对磁盘的访问
优点：更好的利用内存的sort_buffer进行排序操作，尽量减少对磁盘的访问

### order by rand()的问题

直接使用 order by rand()，这个语句需要 Using temporary 和 Using filesort，查询的执行代价往往是比较大的。所以，在设计的时候你要尽量避开这种写法。

尽可能的从业务实现随机

### 索引失效
- 条件字段函数操作
- 隐式类型转换比如原字段是int类型的，查询时使用string。对优化器来说会执行一个string转int的函数。
- 隐式字符编码转换 比如utf8 和 utf8mb4 MySQL优化器会执行CONVERT函数将utf8转成utf8mb4


### 幻读
幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。

#### 如何解决幻读

行锁只能锁住行，但是新插入记录这个动作锁不住。

因此为了解决幻读问题，InnoDB引入新的锁，成为间隙锁。

顾名思义就是两个值之前的空隙(GAP LOCK)

在扫描行时不仅将给行加上锁，还给行两边的空隙也加上间隙锁。

间隙锁和行锁合称next-key lock 每个next-key lock 是前开后闭区间。

加锁规则：
- 原则1： 加锁的基本单位时next-key lock。前开后闭区间。
- 原则2： 查找过程中访问的对象才会加锁。
- 优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。
- 优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。
- 一个bug: 唯一索引上的查询范围会访问到不满足条件的第一个值为止。

### 临时处理MySQL性能
- 先处理掉那些占着连接但是不工作的线程。
- 减少连接过程的消耗。
- 慢查询性能问题
- - 索引没有设计好
- - SQL语句没写好
- - MySQL选错了索引

### 读写分离的坑
#### 主备延迟
解决方案：
- 强制走主库方案
- sleep方案
- 判断主备无延迟方案
- 配合semi-sync方案
- 等主库位点方案
- 等GTID方案

### 如何判断一个数据库是不是出问题了
- 查表判断
- 更新判断
- 内部判断(统计数据等)

### 误删数据怎么办？
#### 使用delete删除数据
- 使用Flashback工具通过闪回把数据恢复回来，要注意语句顺序。
- 做好事前预防，
- - sql_safe_updates 设置为on，这样以来delete或者update语句中写where条件，或者where条件里面没有包含索引字段的话，这条语句的执行就会报错。
- - 代码上线前做好SQL审计。

#### 使用drop table或者truncate table删除表
![](https://static001.geekbang.org/resource/image/2f/db/2fafd0b75286e0163f432f85428ff8db.png)
- 取最近一次全量备份，假设这个库是一天一备。
- 用备份恢复出一个临时库。
- 从日志备份里面取出凌晨0点之后的日志。
- 把这些日志，除了误删数据的语句外，全部应用到临时库。

还有一种办法就是延迟复制备库
延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N命令，可以指定这个备库持续保持跟主库有N秒的延迟。
比如你把N设置为3600，这就代表了如果主库上有数据被误删了，并且在1小时内发现了这个误操作命令，这个命令就还没有在这个延迟复制的备库执行。这时候到这个备库上执行stop slave，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据。

#### drap database 删除数据库
#### rm删除MySQL实例
直接使用备份库就可以。

### 查询很多数据会不会把数据库内存打爆
不会的
- MySQL会将数据放在net_buffer中这块内存的大小是由参数net_buffer_length定义的，默认是16k。
- 重复获取行，知道net_buffer写满,调用网络接口发出去
- 发送成功就清空net_buffer 然后接着取下一行
- 如果发送函数返回EAGAIN或WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送。

也就是说MySQL是*边读边发*


### join 怎么执行的
- 使用join，性能比强行拆成多个单表执行SQL语句性能要好。
- 如果使用join的话需要让小表做驱动表。
但是前提是可以使用被驱动表的索引。

如果可以使用Index Nested-loop Join算法，也就是说可以用上被驱动表上的索引，其实是没问题的；

如果使用Block Nested-Loop Join算法，扫描行数就会过多。尤其是在大表上的join操作，这样可能要扫描被驱动表很多次，会占用大量的系统资源。所以这种join尽量不要用。

可以看explain结果里面，Extra字段里面有没有出现“Block Nested Loop”字样。

### 临时表
- 临时表的语法是create temporary table...
- 一个临时表只能被创建它的session访问，对其他线程不可见。
- 临时表可以与普通表同名
- session A内有同名的临时表和普通表的时候，show create语句，以及增删改查语句访问的是临时表。
- show table命令不显示临时表
- 临时表跟内存表不是一个概念。

#### 临时表的应用
分表的时候从每张表中取到数据汇总排序。

### 什么时候会使用内部临时表
- union
- group by 
- - 如果结果不需要排序可以在SQL语句末尾增加order by null 直接从临时表中取数据
- - 尽量让group by过程用上表的索引，确认方法是explain结果里没有Using temporary 和 Using filesort；
- - 如果group by需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大tmp_table_size参数，来避免用到磁盘临时表；
- - 如果数据量实在太大，使用SQL_BIG_RESULT这个提示，来告诉优化器直接使用排序算法得到group by的结果。

### 自增ID
自增ID可以让主键索引尽量地保持递增顺序插入，避免了页分裂，因此索引更紧凑。
- 在MySQL5.7及之前的版本，自增保存在内存里，并没有持久化。每次重启后第一次打开表的时候，都会去找自增值的最大值。然后+1作为这个表当前的自增值
- - 举例来说，如果一个表当前数据行里最大的id是10，AUTO_INCREMENT=11。这时候，我们删除id=10的行，AUTO_INCREMENT还是11。但如果马上重启实例，重启后这个表的AUTO_INCREMENT就会变成10。﻿
- 在MySQL8.0版本，将自增值的变更记录在redo log中，重启的时候依靠redo log恢复重启之前的值。
### 自增ID用完了会怎么样？

第一个 insert 语句插入数据成功后，这个表的 AUTO_INCREMENT 没有改变（还是 4294967295），就导致了第二个 insert 语句又拿到相同的自增 id 值，再试图执行插入语句，报主键冲突错误。

会报主键冲突。

### 分区表

